# ---- PostgreSQL (in-cluster via kube.yaml) ----
# Recommended when running the stack via `podman play kube kube.yaml`.
# This connects to the Postgres Service name defined in kube.yaml.
PG_HOST=postgresql
PG_PORT=5432
PG_DATABASE=appdb
PG_USER=appuser
PG_PASSWORD=apppassword

# Alternative (host-accessible): prefer a DSN.
# PG_DSN=postgresql://node:node@localhost:5432/test
# (If both are set, PG_DSN wins.)

# Optional: read password from a mounted secret file instead of PG_PASSWORD.
# PG_PASSWORD_FILE=/run/secrets/pg_password

# Connection / execution safety
PG_CONNECT_TIMEOUT=5
PG_STATEMENT_TIMEOUT_MS=5000
PG_MAX_ROWS=200
PG_MAX_SQL_CHARS=20000

# ---- llama.cpp (OpenAI-compatible) ----
# Recommended in-cluster value (llama.cpp server Deployment in kube.yaml).
LLM_BASE_URL=http://llama-cpp-server:11434/v1

# Model id from GET /v1/models (not the .gguf filename)
LLM_MODEL=Qwen3-0.6B-Q8_0

# Required by the openai SDK, ignored by llama.cpp
OPENAI_API_KEY=local
